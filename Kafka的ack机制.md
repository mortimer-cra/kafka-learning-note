这篇文章我们来了解下Kafka的ack机制，在了解ack机制之前，我们先了解下Kafka消息传递语义

## Kafka消息传递语义(Message Delivery Semantics)
对于消息传递语义，一般存在三种类型语义：
1. `At most once` - 消息传递过程中有可能丢失，丢失的消息也不会重新传递，其实就是保证消息不会重复发送或者重复消费
2. `At least once` - 消息在传递的过程中不可能会丢失，丢失的消息会重新传递，其实就是保证消息不会丢失，但是消息有可能重复发送或者重新被消费
3. `Exactly once` - 这个是大多数场景需要的语义，其实就是保证消息不会丢失，也不会重复被消费，消息只传递一次

怎么确定我们的场景是上面三种语义的哪种语义呢？对于Kafka，我们需要从两个方面来论述这个了：
1. 消息发送时的语义
2. 消息消费时的语义

以下分别从这两个方面来讲解下
### 消息发送时的语义
考虑这么一个场景：当`Producer`发送一条消息给Kafka集群中的某个`topic`时，这个时候网络出问题了，那么Kafka会怎么处理呢？

在`0.11.0.0`之前版本的Kafka，因为不知道这条消息是否发送成功，会选择再一次的重发这条消息。这就符合`At least once`语义了，因为遇到网络错误的那条消息可能发送成功了，这个时候如果再重新发送的话，就会导致一条消息被重复发送两次了

在`0.11.0.0`版本开始，Kafka的Producer开始支持了`幂等`发送消息了，其实说白了，就是重复发送一条消息不会导致`broker server`中存储两条一样的消息了。这样的话Kafka在消息的发送的语义就可以达到`Exactly once`了

为了实现`幂等`发送消息，在`0.11.0.0`版本，Kafka给每一个`Producer`一个唯一的ID，以及给发送的每一条消息一个唯一的`sequence number`，利用这两个信息就可以在broker server段对消息进行去重了，这两个字段，我们在 [partition log file.md](partition log file.md) 有提到过

对于生产者的幂等性请参考： [Kafka生产者的幂等性.md](Kafka生产者的幂等性.md) 

### 消息消费时的语义
消费者消费消息的时候是根据`topic + partition + offset`进行消费的，当消费者进程一切正常的时候，这个消费之消费到的`offset`的信息可以存放在消费者进程中的内存中

但是，我们现在来看一个场景：当一个消费者在消费某个`topic`的某个`partition`的时候，突然间这个消费者进程挂了，这个时候我们会再次启动这个消费者进程，我们怎么保证继续从挂了之前消费到的`offset`开始消费消息呢？

我们可以有两种方法来解决上的问题：
1. 消费者可以读取消息，然后将`offset`保存在持久化系统中，然后消息进行处理。那么消费者进程有可能在保存`offset`之后，保存处理消息的结果之前挂掉了，在这种情况下，当消费者进程重新启动后，就会从已经存储的`offset`开始消费消息并处理消息了，挂掉之前的消费者进程处理消息的结果可能还没来得及保存，所以在这种情况下，有一些消息就可能没有得到处理了，那么，这种场景是符合`At most once`语义的，因为当消费者进程挂了之后，有些消息可能得不到处理
2. 消费者可以读取消息，然后处理消息，将处理之后的结果进行保存，最后再保存消费到的消息`offset`了。那么消费者进程有可能在保存消息处理结果之后，保存消费到的消息`offset`之前挂了，这种情况下，当消费者进程重新启动的时候，则从上一次保存的消费的消息的`offset`开始处理消息了，这个时候就可能会导致重复处理消息了，因为在挂掉之前可能有部分数据处理成功了。那么这种场景符合`At least once`语义了，因为没有漏掉处理消息，但是有可能重复处理消息了

Kafka默认可以保证`At least once`的语义，也就是上面的第二种场景了。

如果你想实现`At most once`语义的话，那么你需要做：
1. 首先要禁用掉`Producer`端的`retry`机制(消息重发)，即将`Producer`的配置`retries`置为`0`
2. 在消费者进程中，先将消费到的消息的`offset`先保存在持久化系统中，然后再开始处理消息，并保存处理结果

那么咋Kafka中怎么做到消费者消费消息时的`Exactly once`的语义呢？针对不同的场景，有下面三种方法：
1. 可以在`At least once`语义的基础之上，在消费者进程中保存处理结果的时候采用`幂等`的保存方法，举个例子：比如将结果保存到MySQL的某张表中，这张表有一个字段是`唯一`的(你可以认为这个字段就是这张表的`主键`)，那么在消费者进程保存处理结果的时候，如果这个唯一的字段的值已经存在了，则不会再保存这个结果了，这样就保证保存的结果不会重复了
2. 如果我们协调好消费者`消费的消息offset的保存`和`处理消息结果的保存`之间的关系就可以达到`Exactly once`的语义，就是说，当`消费的消息offset的保存`成功以及`处理消息结果的保存`成功，则算成功，如果两者有一个失败的话，那么就需要回滚两个保存了(是不是和事务有点像)，我们可以用下面三种方法来协调这两者之间的关系：
    1. [two-phase commit](https://www.cnblogs.com/sunddenly/articles/4072882.html)
    2. [使用Kafka的事务](Kafka生产者事务详解.md)
    3. 将`offset`和处理结果保存在同一个地方，这样的话，要么都保存失败，要么都保存成功，这种方式是比较简单的，将Kafka中的数据导入到HDFS的Kafka Connector就是这样来实现的，用兴趣可以看[这里的源码](https://github.com/confluentinc/kafka-connect-hdfs/blob/d8f98e3cca7509d80d40982f6a962b90f183a6c3/src/main/java/io/confluent/connect/hdfs/HdfsSinkTask.java#L99)

### 总结
1. Kafka默认的语义是`At least once`，消费者进程消费消息并处理完后，会保存到Kafka的Broker Server上，详细请看 [Kafka消费者的offset的存储.md](Kafka消费者的offset的存储.md) 
2. 如果你想实现`At most once`语义的话，那么你需要做：禁用掉`Producer`的消息重发机制以及先于保存处理结果，然后将`offset`保存到持久化系统中
3. 如果我们协调好消费者`消费的消息offset的保存`和`处理消息结果的保存`之间的关系就可以达到`Exactly once`的语义

## ack机制
在`Producer`向`Kafka`集群发送一条消息的时候，如果消息发送失败的话，并且我们设置了`retries`属性的话，`Producer`有重新发送消息的机制，这种机制主要是提高消息的发送成功率

如果我们想`Producer`发送的消息一定能发送成功，不会丢失的话，除了上面的消息重发机制，还有就是`ack机制`。

我们在了解[Kafka的ISR机制](http://note.youdao.com/noteshare?id=6337e9a7b8786a46fa75dd804f4610dc&sub=CC92E76AD3134D0A8C5856CBE0EF27C7)的时候，我们已经知道了，一个`topic`可以分成多个`partition`，每一个`partition`可以有多个副本，在多个副本中有一个`Leader副本`和若干个`Follower副本`，`Leader副本`提供这个分区消息的读写服务

如果`Producer`发送了一条消息，这个消息如果已经发送并存储在`Leader副本`中的日志文件中，那其实就可以说明这条消息已经发送成功了，但是如果这个`Leader副本`可能会挂掉，所以数据只存储在`Leader副本`也不能保证数据不会丢，所以有的时候`Producer`需要等到发送的消息都存储到`ISR`列表中的备份的时候才算成功，这个时候消息就不容易丢失了

根据上面的特点，`Producer`在发送消息的时候就可以指定`acks`的值了，`acks`值可以是`[ 0, 1, -1, all]`。
- 当`acks=0`的时候，`Producer`发送消息到发送端的`buffer`中就直接返回了，至于这个消息有没有真的发送到`Broker Server`，`Producer`不关心，即使消息发送失败，上面说的`retry`机制也不起作用，所以在这种场景下，可能就会丢失消息了，如下图：
![image-20200527111725118](https://raw.githubusercontent.com/mortimer-cra/mypic/master/img/20200527111725.png)
- 当`acks=1`的时候，`Producer`发送的消息一定要存储到对应的分区的`Leader副本`日志文件中才算消息发送成功，要是失败的话，则会尝试`retry`。在这种场景下，只有当消息已经存储在`Leader副本`中，但是消息还没有被`Follower副本`同步的时候，如果`Leader副本`所在的broker server挂了，消息才会丢失，如下图：
![image-20200527111746741](https://raw.githubusercontent.com/mortimer-cra/mypic/master/img/20200527111846.png)
- 当`acks=-1或者等于all`的时候，`Producer`发送的消息一定要存储到对应的分区的所有的在`ISR列表`中的副本日志文件中才算消息发送成功，要是失败的话，则会尝试`retry`。这种场景下消息就很难丢失了，除非所有的副本所在的`Broker Server`都挂了，如下图：
![image-20200527111902349](https://raw.githubusercontent.com/mortimer-cra/mypic/master/img/20200527111902.png)

> `acks`是英文单词`acknowledgments`的缩写，可以表示响应，即消息发送端发送消息给Kafka集群得到的响应，比如`acks=all`的时候，只有所有的`ISR`副本存储好消息之后才给客户端一个响应，表示消息存储成功

`acks`上面的三种取值可以根据你的业务需求来设置，消息的持久性是越来越强的，但是性能肯定越来越差的，上面的三种取值就是在消息持久性和性能两个方面做一个权衡